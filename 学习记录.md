<h1 style="text-align:center;font-weight:bold;">学习记录</h1>

------

## **Linux常用命令：**

- #### **查看系统资源等：**

|      查看系统内存      |    free-h     |
| :--------------------: | :-----------: |
|      查看磁盘空间      |     df -h     |
|        查看CPU         |    name -a    |
|      查看cpu信息       |     lscpu     |
|      查看系统负载      | uptime 或 top |
| 进一步查看进程更多信息 |    ps -ef     |
|      结束异常进程      |  kill -9 PID  |

## **Ubuntu中对U盘进行格式化操作：**

主要是FAT32文件系统只支持单个文件最大4GB，因此需格式化为exfat格式。

- #### 方法：

|                         识别U盘设备                          |                        sudo fdisk -l                         |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
|                          记录分区名                          |                          /dev/sdc1                           |
|                           卸载分区                           |                       umount /dev/sdc1                       |
| 查看系统型号，并查看是否安装exfat工具，如果没有则需要根据型号安装对应的工具 | `sudo apt update  sudo apt install exfat-utils exfat-fuse `（20.04） |
|                          格式化U盘                           |           sudo mkfs.exfat -n "BY_NOVE25" /dev/sdc1           |
|                           安全移除                           |                     sudo eject /dev/sdc1                     |

## **==Product_Redesign分类拼接==**

**GPT2-Xlnet-Cbow-skipgram-glove**

**具体作用：**

- **GPT‑2**: 只用了输入词嵌入矩阵 wte（即 token embedding）。用 gpt2_tokenizer 得到的 input_ids 查表成向量，随后对序列做均值池化；没有走 GPT‑2 的 Transformer 编码层和位置编码。
- **XLNet (xlnet-based-cased)**: 只用了 word_embedding（token embedding）。同样是查表→均值池化；没有经过 XLNet 的编码层。
- **GloVe**: 载入 6B-300d 英文词向量，转换成 nn.Embedding.from_pretrained(...)，用 basic_english 分词得到 token，再查表→均值池化。
- **fastText CBOW**: 用 cc.en.300.bin 的 get_input_matrix() 作为 nn.Embedding 权重，通过 ft.get_word_id 取词 id，查表→均值池化。
- **fastText Skip‑gram**: 同 CBOW，但权重来自 wiki.en.bin，流程相同→均值池化。

上述5路序列均值后的向量被拼接（concat）后，送入一个单层全连接 Linear(..., num_classes) 做分类。代码中把这些层设为半精度 half()，默认参与训练（未冻结）。

**如何做：**

- 用专利语料对中文 RoBERTa/ERNIE/BERT 继续预训练再做“无人机评论特征分类”是“有可能小幅提升、但不稳”的做法。
- 若你的评论文本较“技术化”（参数/续航/载荷等专业词），收益更可能为正；若更口语化/情感化，和专利域差异大，收益可能有限甚至略降。
- 方法本身合理（属于领域自适应预训练 DAPT），但你的目标域是“消费类评论”，与“专利”差异较大。单做“专利 DAPT”并不理想。更合理的是：
- 先做专利 DAPT（可保留技术词表能力），再做“目标评论语料的无监督继续预训练”（TAPT），或者直接只做 TAPT。或者按一定比例混合评论:专利（如 3:1）一起做继续预训练，减少域偏移。

### 建议做法（最短路径）

- 收集尽可能多的无人机评论原始文本（无标签也行），对同一基础模型做 1–3 轮 MLM 继续预训练（TAPT），再进行分类微调。
- 若已有“专利 DAPT”权重，可在其基础上再做“评论 TAPT”（两段式：Patent → Review），通常优于只用专利 DAPT。
- 不改 tokenizer/vocab，保持与原模型一致；只做 MLM（不需要 NSP/句对等）。

### 训练细节建议

- 学习率和步数：TAPT/DAPT 通常 10k–50k steps、小 LR（2e-5～5e-5），监控验证困惑度或下游开发集指标，避免过训和灾难性遗忘。
- 防遗忘/稳健性：可用 Adapter/LoRA 做继续预训练与下游微调；或分段解冻、只训练后几层。
- 数据混合：若保留专利知识又需贴合评论域，可按评论:专利=3:1 或 4:1 混洗做继续预训练。
- 评估对比（必须做）：Base（不预训） vs 仅专利 DAPT vs 仅评论 TAPT vs 专利→评论（DAPT→TAPT）。以 F1/Recall 为主选型。

### 模型选择提示

- 中文分类通常 RoBERTa-wwm 系列更稳，ERNIE 表现相近，BERT-base-Chinese作基线。三者都适合做 DAPT/TAPT。
- 你已用24万条专利继续预训练：若平均长度可观，这一规模足够支撑“少轮数”的 DAPT。建议再补一段评论 TAPT，收益更确定。
- 风险与对策：专利含大量英文编号/公式，域偏移明显；用混合训练或二阶段 TAPT可缓解；严格做消融对比，防止“看似提升实则过拟合”。

小结

- 仅“专利 DAPT”用于无人机评论分类：可行但收益不稳。
- 最佳实践：在此基础上再做“评论 TAPT”，或用评论为主的混合继续预训练；再微调分类，通常能稳定提升。

- 只用“专利摘要”做继续预训练，相比包含编号/公式的全文，域差距更小、更接近自然语言，**更有可能带来正向增益**，尤其是技术属性相关的评论分类（如续航、载荷、相机/云台、抗风、定位等）。
- 但和消费类评论仍有差异（口语、情感、俚语、品牌型号、价格词）。要想稳定提升，建议在“摘要 DAPT”后再做一段“评论无监督继续预训练（TAPT）”。

### 预期效果（经验判断）

- 若标签聚焦技术与性能维度，且评论中常出现技术术语，**更可能提升**（宏平均 F1 提升约 1–3+，视数据而定）。
- 若评论更口语/情绪化，纯“摘要 DAPT”收益可能有限；加一段“评论 TAPT”通常会把收益拉稳。

### 建议落地做法

- 保留你现有的摘要 DAPT 权重，再对大规模无人机评论（无标签也可）做 1–3 轮 MLM 的 TAPT，然后再用标注集做分类微调。
- 若评论语料有限，可按“评论:摘要 ≈ 3:1 或 4:1”混合继续预训练，降低域偏移。
- 不改 tokenizer/vocab；仅做 MLM。可用 LoRA/Adapter 避免灾难性遗忘。

### 训练与评估要点（精简）

- 学习率与步数：2e-5～5e-5，1e4～5e4 steps（视语料与batch而定）；监控验证困惑度/下游 dev 指标，早停。
- 序列长度：评论任务多为短文本，128～256 足够。
- 评估对比：Base → 仅摘要 DAPT → 仅评论 TAPT → 摘要 DAPT→评论 TAPT。以宏 F1/Recall 选型。
- 风险控制：若下游指标不升反降，减少 DAPT 步数、加上 TAPT 或仅做 TAPT；或采用参数高效方法（LoRA）与分层解冻。

小结

- 用“专利摘要”继续预训练是**合理且更稳**的选择，比用整篇专利噪声小。配合一段“评论 TAPT”，通常能让无人机评论特征分类更稳定、提升更可预期。

- 只做评论语料的无监督继续预训练（TAPT）：建议收集 5–20M 中文 token（约 5万–15万条平均100–150字的评论）。低于 1–3M token 也能起效，但波动更大；超过 ~30M token 回报趋缓。
- 做分类微调（你是3分类）：标注数据建议每类 1k–2k 条为较稳区间；可用但偏少的下限是每类 300–500 条；更稳健则 3k+/类。

### 细化建议

- 评论 TAPT（无标签）：
- 最小有效量：10k–20k 评论（≈1–3M token）。
- 推荐量：50k–150k 评论（≈5–20M token）。
- 若样本多样性高、子场景多，可到 200k–300k；再多收益有限。
- 粗算：中文 BERT 多为字级/子词级，100–150字/条 ≈ 100–150 token；10万条 ≈ 1000–1500万 token，正好落在推荐区间。
- 标注集（下游分类微调）：
- 3分类：
- 可用下限：300–500/类（需好调参＋正则化）。
- 稳定区间：1k–2k/类。
- 更强鲁棒：3k+/类或困难类别加量。
- 若类别更多（≥10类）：尽量 ≥500/类；长尾类至少 200/类，否则使用类权重/焦点损失/少样本增强。
- 已有“专利摘要 DAPT”的前提下：
- 再做“评论 TAPT”通常比只做 DAPT 更稳更增益；也可评论:专利 ≈ 3:1 混合继续预训练。
- 若标注较少，优先做 TAPT，并考虑 LoRA/Adapter 等参数高效微调。
- 其他实操要点：
- 序列长度 128–256 足够多数评论；控制 tokens 总量更关键。
- 去重、去模板与清洗噪声，比单纯“再多点量”更划算。
- 评估务必做对照：Base → 仅DAPT → 仅TAPT → DAPT→TAPT，以宏 F1/Recall 选型。

小结

- 无标签评论：优先冲到 5–20M token（约 5万–15万条）；
- 有标签分类：3类任务尽量 1k–2k/类，最低 300–500/类可启动。

##

|      |      |
| ---- | ---- |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |
|      |      |

## **==Bert_Modedl_Pretrain==**

- Parametr Setting:

保存.bin文件的方法: --save_safetensors=False

## **==Conda Command:==**

|             conda-v             |       查看版本信息       |
| :-----------------------------: | :----------------------: |
|       conda updata conda        |         更新版本         |
|         conda env list          |         更新版本         |
| conda create -n  xxx python=xxx | 创建固定版本的conda'环境 |
|       conda activate xxx        |       激活虚拟环境       |
|        conda deactivate         |         退出环境         |
|           conda list            |    当前环境下安装的包    |

| **删除环境：两步实现**: 1. conda deactivate 2. conda remove -n xxx --all |
| ------------------------------------------------------------ |

## **erine断点训练记录：**

复制任意保存的checkpoint文件夹中的trainer_state.json文件到主训练目录中即可。

## **==Pycharm服务器配置记录==**

**notebookbook：使用相对路径时，应在代码开头将路径切到项目根目录，后续的路径使用最简相对路径即可。——2025.09.11**
**即：**%cd "/mnt/ubuntu_disk/......

- #### **==Pycharm中使用jupyter notebook连接远程服务器的方法：==**

1. 在远程服务器中输入： jupyter notebook  --allow-root/

   使用远程服务器的jupyter notebook：
   ① screen
   ② 按照正常终端输入上面的命令
   （使用screen的原因是可以使用终端长期执行命令）

2. 在本地终端输入：
   -i ~/.ssh/autodl-key-P 端口 -L 8899:07.0.0.0: 8889 root @ connect.nmbl.seetacloud.com 
   （映射端口），后面地址为服务器的登录地址

3. Pycharm中-- Tools -- jupyter Connection 添加URL,token为修改的固定token（可网上查如何修改）
   注意：如果jupyter 内核无法选择，实际上使用的是base下面的内核，可在服务器的`Root/miniconda3/share/jupyter/Kernels/`修改Kernel.json文件中python解释器的地址为创建的虚拟环境地址。

   

## **==Neo4j USE==**

|    // 查看所有节点    |                    MATCH (n) RETURN n;                     |
| :-------------------: | :--------------------------------------------------------: |
| // 查看特定类型的节点 | MATCH (n:Person) RETURN n;MATCH (n:Organization) RETURN n; |
| // 查看特定类型的关系 |          MATCH (n)-[r:工作于]->(m) RETURN n,r,m;           |
|    // 删除所有关系    |                 MATCH ()-[r]-() DELETE r;                  |
|    // 删除所有节点    |                    MATCH (n) DELETE n;                     |

# **==Doccano USE==**

1. 初始化数据库: doccano init
2. 创建一个super user。这里要把pass改成你需要的密码。当然，用户名也可以改成别的。
   doccano createuser --username admin --password pass
3. 启动webserver: doccano webserver --port 8000
   然后，打开另一个终端，运行下面的代码启动任务队列：
4. 启动任务队列: doccano task
5. \#打开窗口: http://127.0.0.1:8000

# **==GPT-GNN项目==**

# **训练参数设置及训练阻塞问题：**



- 学习率为 1e -3合适，增加为0.002时无法训练
- 从batch_size,学习率等参数逐步挨个调试找出合适能跑动的参数
- 最佳参数：
- +--------------------+---------------------------------------------------------+
  | Parameter          | Value                                                   |
  +--------------------+---------------------------------------------------------+
  | attr_ratio         | 0.500                                                   |
  +--------------------+---------------------------------------------------------+
  | attr_type          | text                                                    |
  +--------------------+---------------------------------------------------------+
  | neg_samp_num       | 255                                                     |
  +--------------------+---------------------------------------------------------+
  | queue_size         | 256                                                     |
  +--------------------+---------------------------------------------------------+
  | w2v_dir            | /mnt/ubuntu_disk/GPT-                                   |
  |                    | GNN_ubuntu/datadrive/dataset/w2v_all                    |
  +--------------------+---------------------------------------------------------+
  | data_dir           | /mnt/ubuntu_disk/GPT-                                   |
  |                    | GNN_ubuntu/datadrive/dataset/graph_CS.pk                |
  +--------------------+---------------------------------------------------------+
  | pretrain_model_dir | /mnt/ubuntu_disk/GPT-                                   |
  |                    | GNN_ubuntu/datadrive/models/test/pretrain_OAG.pt        |
  +--------------------+---------------------------------------------------------+
  | cuda               | 0                                                       |
  +--------------------+---------------------------------------------------------+
  | sample_depth       | 6                                                       |
  +--------------------+---------------------------------------------------------+
  | sample_width       | 64                                                      |
  +--------------------+---------------------------------------------------------+
  | conv_name          | hgt                                                     |
  +--------------------+---------------------------------------------------------+
  | n_hid              | 400                                                     |
  +--------------------+---------------------------------------------------------+
  | n_heads            | 8                                                       |
  +--------------------+---------------------------------------------------------+
  | n_layers           | 3                                                       |
  +--------------------+---------------------------------------------------------+
  | prev_norm          | False                                                   |
  +--------------------+---------------------------------------------------------+
  | last_norm          | False                                                   |
  +--------------------+---------------------------------------------------------+
  | dropout            | 0.200                                                   |
  +--------------------+---------------------------------------------------------+
  | max_lr             | 0.001                                                   |
  +--------------------+---------------------------------------------------------+
  | scheduler          | cycle                                                   |
  +--------------------+---------------------------------------------------------+
  | n_epoch            | 10                                                      |
  +--------------------+---------------------------------------------------------+
  | n_pool             | 8                                                       |
  +--------------------+---------------------------------------------------------+
  | n_batch            | 32                                                      |
  +--------------------+---------------------------------------------------------+
  | batch_size         | 128                                                     |
  +--------------------+---------------------------------------------------------+
  | clip               | 0.500                                                   |
  +--------------------+---------------------------------------------------------+

#### **pretrain_OAG_train_log 修改记录：**

使用codex修改：

请查看我的代码，我需要两个功能：

1. 控制台的输出带有时间戳

2.控制台输出的同时将日志保存到本地
3.只在主进程中输出和保存日志，避免重复输出和打印
请仔细查看代码，进行以上功能的添加，但是尽量保持代码简洁

## 日志改进

- 新增 setup_logging：配置带毫秒时间戳的日志格式，同时输出到控制台和本地文件，并避免重复添加处理器。
- 更新 print_with_time：统一通过 logger 输出，并在子进程中直接返回，确保只有主进程写日志。
- 扩展 args_print 支持自定义输出函数，让参数表也走带时间戳的日志通道。

## **具体：**

```
logger = logging.getLogger('pretrain_oag')
logger.setLevel(logging.INFO)
logger.propagate = False
_logging_configured = False

def setup_logging(log_path):
    global _logging_configured
    if _logging_configured:
        return
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    formatter = logging.Formatter('[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    stream_handler = logging.StreamHandler(sys.stdout)
    stream_handler.setFormatter(formatter)
    file_handler = logging.FileHandler(log_path, encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.handlers.clear()
    logger.addHandler(stream_handler)
    logger.addHandler(file_handler)
    _logging_configured = True

def print_with_time(message):
    if mp.current_process().name != 'MainProcess':
        return
    if _logging_configured:
        logger.info(message)
    else:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
        print(f"[{timestamp}] {message}")
if __name__ == '__main__':

    from GPT_GNN.utils import args_print

    log_dir = os.path.dirname(args.pretrain_model_dir) or os.getcwd()
    log_path = os.path.join(log_dir, f"{os.path.splitext(os.path.basename(__file__))[0]}.log")
    setup_logging(log_path)

    args_print(args, print_fn=print_with_time)
```

#### **utils.py中：**

```
def args_print(args, print_fn=None):
    _dict = vars(args)
    t = Texttable()
    t.add_row(["Parameter", "Value"])
    for k in _dict:
        t.add_row([k, _dict[k]])
    output = t.draw()
    if print_fn is None:
        print(output)
    else:
        for line in output.splitlines():
            print_fn(line)
```

#### **pretrain_OAG_linux_train_log修改记录：**

### **报错：**

Traceback (most recent call last):
File "/home/ubuntu/GPT-GNN/example_OAG/pretrain_OAG_linux__train_log.py", line 475, in <module>
main()
File "/home/ubuntu/GPT-GNN/example_OAG/pretrain_OAG_linux__train_log.py", line 299, in main
randint(0, 2**31 - 1),
TypeError: randint() takes 0 positional arguments but 2 were given

### **原因：**

这是一个 Python 的 TypeError。程序在调用 randint(0, 2**31 - 1) 时，解释器发现当前作用域里的 randint 函数被定义成不接受位置参数（即它的签名是 randint()），但你传入了两个位置参数，所以抛出了 “takes 0 positional arguments but 2 were given” 的异常。通常出现在：
错误地覆盖了原本应该调用的 randint，例如自己写了一个同名函数或变量；
或者导入了不对的 randint（例如从别的模块拿到了一个不需要参数的版本）。

### **处理：**

主要改动：把 randint 改为使用 GPT_GNN.utils 里的实现，并按该函数签名（无参数）调用，避免调用 random.randint 时传参导致的 TypeError。
在 pretrain_OAG_linux__train_log.py 里移除 from random import randint。
改成 from GPT_GNN.utils import args_print, ndcg_at_k, randint。
三处调用改为 randint()

### **代码中：**

from GPT_GNN.utils import args_print, ndcg_at_k, randint
…
jobs.append(pool.apply_async(
GPT_sample,
args=(randint(), pre_target_nodes, pre_range, args.batch_size, feature_OAG)
))
…
data, rem_edge_list, ori_edge_list, _, _ = GPT_sample(
randint(),
pre_target_nodes,
pre_range,
args.batch_size,
feature_OAG
)

Linux最佳参数：

[2025-09-26 17:04:38.934] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.934] | Parameter          | Value                                                  |
[2025-09-26 17:04:38.934] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.934] | attr_ratio         | 0.500                                                  |
[2025-09-26 17:04:38.934] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.934] | attr_type          | text                                                   |
[2025-09-26 17:04:38.934] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | neg_samp_num       | 255                                                    |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | queue_size         | 256                                                    |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | w2v_dir            | /home/ubuntu/GPT-GNN/datadrive/dataset/w2v_all         |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | data_dir           | /home/ubuntu/GPT-GNN/data/oag_output/graph_CS.pk       |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | pretrain_model_dir | /home/ubuntu/GPT-GNN/datadrive/models/test/pretrain.pt |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | cuda               | 0                                                      |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | sample_depth       | 4                                                      |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | sample_width       | 64                                                     |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | conv_name          | hgt                                                    |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | n_hid              | 400                                                    |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | n_heads            | 8                                                      |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | n_layers           | 3                                                      |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | prev_norm          | True                                                   |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | last_norm          | True                                                   |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | dropout            | 0.200                                                  |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | max_lr             | 0.001                                                  |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | scheduler          | cycle                                                  |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | n_epoch            | 10                                                     |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.935] | n_pool             | 3                                                      |
[2025-09-26 17:04:38.935] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.936] | n_batch            | 32                                                     |
[2025-09-26 17:04:38.936] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.936] | batch_size         | 256                                                    |
[2025-09-26 17:04:38.936] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.936] | clip               | 0.500                                                  |
[2025-09-26 17:04:38.936] +--------------------+--------------------------------------------------------+
[2025-09-26 17:04:38.936] | start_method       | spawn                                                  |
[2025-09-26 17:04:38.936] +--------------------+--------------------------------------------------------+

128g内存占用率：83%（约104g）

ssh-keygen -t ed25519 -C "1970318886@qq.com"

![image-20251107160812100](/home/ll/.config/Typora/typora-user-images/image-20251107160812100.png)

passphrase:8023





